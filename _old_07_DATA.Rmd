# Data Retrieval, Preparation & Analysis {#Chapter-DATA}


## Climate Reanalysis Data {#Data::ClimateReanalysisData}

Information about the spatio-temporal distribution of precipitation (P) and temperature (T) is vital for water balance studies, including for modeling. Poorly gauged basins do not have dense enough ground-based monitoring network that would allow to obtain reliable meteorological fields that can be used to drive hydrological models. Station data are especially poor in complex and remote mountain catchments in developing and transition countries. The Central Asian river basins are examples of such basins. Global reanalysis data can help to cover these existing gaps. In this Chapter, we show how this can be achieved.

We use ERA5 global reanalysis data to obtain temperature at 2 meters above ground and total precipitation fields on an hourly base from 1981-01-01 through 2020-12-31. ERA5 data comes with a 30km grid cell size resolution and is thus quite course. This is relevant for complex mountain terrains which feature highly variable climate over very short distances, sometimes from one valley to the next. To address this problem, a bias correct version of the monthly CHELSA high resolution climatology product is used to arrive at high resolution hourly climatology fields (the CHELSA dataset is described in [@Karger_2017] and the bias correction of it in [@beck2020a]. Like this, high-resolution hourly data from 1981-01-01 through 2013-12-31, i.e. the period for which the CHELSA dataset is available, could be derived. These data are then used for model calibration and validation and for the computation of the reference hydro-climatological situation from 1981 through 2013. More details can be found in Chapter \@ref(RSMinerveMODELS).

The analysis present here is for the Gunt river catchment. The approach and methods we have developed are universally applicable for other catchments.

### CHELSA V1.2.1 Data and Bias Correction {#Data::CHELSA}

The CHELSA V1.2.1 data covers the period 1981-01-01 until 2013-12-31. This period is considered to be the base climate period where 1981-01-01 until 1993-12-31 will be used as the parameter calibration period for the hydrological model. The model validation period is from 1994-01-01 until 2013-12-31. This period will constitute the baseline period in relation to which climatic changes in the mid 21st as well as end of 21st century will be assessed.

Mean monthly temperature and total monthly precipitation between 1981-01-01 and 2013-01-01 can be accessed and downloaded for the Central Asia domain from the following [online repository](https://www.dropbox.com/sh/zfwfhw6rnq04k0l/AABuhwT5clmV_vprEoXWPp-pa?dl=0)[^data-3]. Mean monthly temperatures are stored in the `./t2m/` folder and precipitation in the `./pr/` folder there.

[^data-3]: Please note that the total size of this repository is 2 GB, approximately. Prior to downloading these data, you should ensure that you have enough storage space on your local machine. Furthermore, it is advised that you create the directory structure in the following way:

    **FILES/PROJECT**\
    -**Code**\
    ---yourRProject.Rproj\
    ---code1.R\
    ---...\
    -**HydrologicalModeling_CentralAsia_Data**\
    ---\

    where FILES/PROJECT is the folder where you keep your documents on your computer and project denotes the folder name of your project, Code is the folder where all your code lives and HydrologicalModeling_CentralAsia_Data is the folder where you store all the accompanying data that can downloaded.

Note that the Central Asia domain is defined as test

```{r}
aoi_CentralAsia_LatLon <- extent(c(65,80.05,35.95,44.05)) # this is a raster::extent() object. For more information, type ?extent into the console.
```

The CHELSA data are downscaled ERA-INTERIM model outputs for temperature and precipitation with a resolution of 30 arc seconds [@Karger_2017]. Temperature fields are statistically downscaled ERA-INTERIM temperatures whereas for precipitation downscaling, several orographic predictors are taken into account, including for example wind fields, valley exposition, height of the atmospheric boundary layer, etc.

Because of its highly resolved climatologies, the CHELSA data has been shown to be particularly useful for studies in regions with complex topography. However, it has also been shown that the original CHELSA precipitation data is underestimating high mountain precipitation. This can be explained by the phenomenon of snow undercatch which explains measured precipitation deficits by sublimation and blowing snow transport at high altitude meteorological stations.

An example of this is shown in Figure \@ref(fig:snowUndercatchExampleSpain) for high elevation gauges in Spain. In a recent intercomparison project carried out in Spain, it has been shown that undercatch poses significant problems in accurately measuring solid precipitation [@Buis_n_2017] in mountainous regions. Both, ERA-INTERIM and CHELSA themselves assimilate station data in their models and hence are affected by these *erroneous* measurements.

```{r snowUndercatchExampleSpain, echo = FALSE, fig.cap="Measured snow undercatch values in high-mountain stations in Spain. The values were determined within the World Meteorological Organization Solid Precipitation Intercomparison Experiment (WMO-SPICE). See text for more information and reference."}
knitr::include_graphics('_bookdown_files/FIG_DATA/snowUndercatch_Spain.jpg')

```

@beck2020 has recognized this and released monthly correction factors for the CHELSA data (see Figure \@ref(fig:CHELSABiasCorrectionFactors)).

```{r CHELSABiasCorrectionFactors, echo=FALSE, fig.cap="Figure from [@beck2020], Supplementary Material. Plate d): Best estimate of global bias correction factors. Plate e): Lower bound estimate of global bias correction factors. Plate f): Upper bound of global bias correction factors. As is clearly visible, bias correction factors in high-mountain Asia, including the parts of Central Asia are significant."}
knitr::include_graphics('_bookdown_files/FIG_DATA/Beck_BiasCorrectionFactors.jpg')
```

The bias corrected CHELSA precipitation (tp) raster data is available via this Dropbox [link](https://www.dropbox.com/s/zysif93xbbay2tp/CHELSA_V12.nc?dl=0). Using these temperature as well bias-corrected precipitation data, we can easily compute and display the monthly norm climatology fields over the Central Asia domain[^data-4]. Here, we just load them and visualize the mean monthly patterns for a consistency check.

[^data-4]: The code for the computation of the CHELSA long-term monthly mean temperature and precipitation climatologies is provided in the Appendix C in the corresponding Sect.

```{r meanMonthlyTemperatureClimatology, warning=FALSE, fig.cap="CHELSA v1.2.1 mean monthly temperature climatology is shown."}
t2m_meanMonthlyClimate_CHELSA <- 
  raster::brick('./data/CentralAsiaDomain/CHELSA_V1.2.1/t2m_climatology/t2m_climatology_CA.tif')

names(t2m_meanMonthlyClimate_CHELSA) <- month.abb
t2m_meanMonthlyClimate_CHELSA <- t2m_meanMonthlyClimate_CHELSA / 10 - 273.15 # now, the CHELSA data is in deg. C

temperature_colors <- brewer.pal(9, "RdYlBu") %>% colorRampPalette()

gplot(t2m_meanMonthlyClimate_CHELSA) + 
  geom_tile(aes(fill = value)) +
  facet_wrap(~ variable) +
  scale_fill_gradientn(colours = rev(temperature_colors(5))) +
  coord_equal() +
  guides(fill=guide_colorbar(title='T [deg. C.]')) 
```

In a similar way, the bias corrected precipitation climatology can be plotted. Figure \@ref(fig:meanMonthlyPrecipitationClimatology) nicely shows the main precipitation months of the key mountain ranges in the region. The Figure shows that March and April are normally the main precipitation months.

```{r meanMonthlyPrecipitationClimatology, warning=FALSE, fig.cap="CHELSA v1.2.1 mean monthly precipitation climatology is shown."}
# Load file
pbcorr_pr_meanMonthlyClimate_CHELSA <- 
  raster::brick('./data/CentralAsiaDomain/CHELSA_V1.2.1/pr_climatology/pr_climatology_CA.nc')
# Layer names
names(pbcorr_pr_meanMonthlyClimate_CHELSA) <- month.abb
# Color palette
precipitation_colors <- brewer.pal(9, "YlGnBu") %>% colorRampPalette()
# Plot
gplot(pbcorr_pr_meanMonthlyClimate_CHELSA) + 
  geom_tile(aes(fill = value)) +
  facet_wrap(~ variable) +
  scale_fill_gradientn(colours = precipitation_colors(500)) +
  coord_equal() +
  guides(fill=guide_colorbar(title='P [mm/yr]')) 
```

How can the quality of the CHELSA data in the complex Central Asia domain be assessed? We explore this question the validity of the CHELSA dataset to be able to adequately represent the high-mountain climate in the Pamirs. The key questions here to be answered are

-   does the magnitude of the precipitation yield physically meaningful results, and

-   does the climatology adequately reproduce the seasonal cycle observed one at the stations?

Let us address the first question investigating bias corrected precipitation values and comparing these discharge for the Gunt river basin. If $P >Q$ where $P$ is the long-term mean precipitation and $Q$ is the long-term mean discharge, we can confidently say that the bias corrected CHELSA precipitation product is meaningful from a water balance perspective (see also Chapter \@ref(LongTermWaterBalance) for more information).

```{r guntCHELSAPreciptiation, warning = F,message = F, fig.cap = "Long-term mean precipitation climatology of the Gunt river basin in the Pamir mountains. The catchment is delineated by the black polygon. The mean long-term precipitation in the catchment is 349 mm/year."}
# Load catchment shp
gunt_Shapefile <- st_read('./data/AmuDarya/Gunt/GeospatialData/Gunt_Basin_poly.shp',quiet = TRUE)
gunt_Shapefile <- gunt_Shapefile %>% subset(fid==2)
gunt_Shapefile_LatLon <- st_transform(gunt_Shapefile,crs = st_crs(4326))
areaGunt <- gunt_Shapefile %>% st_area() %>% as.numeric()

# Areas of Interest
aoi_CentralAsia_LatLon <- extent(c(65,80.05,35.95,44.05)) # in lat/lon
aoi_Basin_LatLon <- gunt_Shapefile_LatLon %>% extent() # GUNT
aoi_Basin_UTM <- gunt_Shapefile %>% extent() # GUNT, in UTM

fLoc <- './data/AmuDarya/Gunt/ReanalysisData/tp_bcorr_NORM_CHELSA_Gunt.nc'
chelsaP_GUNT_corr_raster <- brick(fLoc, varname="corr_P_annual")

chelsaP_GUNT_corr__spdf <- as(chelsaP_GUNT_corr_raster, "SpatialPixelsDataFrame")
chelsaP_GUNT_corr__df <- as.data.frame(chelsaP_GUNT_corr__spdf)
colnames(chelsaP_GUNT_corr__df) <- c("value", "x", "y")

# Plot the raster for inspection and analysis
ggplot() +
  geom_tile(data=chelsaP_GUNT_corr__df, aes(x=x, y=y, fill=value), alpha=0.8)+
  geom_sf(data=gunt_Shapefile,color="black",fill=NA) +
  scale_fill_gradientn(colours = precipitation_colors(5)) + 
  xlab("Longitude") + ylab("Latitude") + 
  guides(fill=guide_colorbar(title="P Norm [mm]")) + 
  ggtitle("Bias Corrected CHELSA v1.2.1 Norm Precipitation, Gunt River Basin")

# Extract raster values inside basin polygon and convert to equivalent water height
rasterRes <- chelsaP_GUNT_corr_raster %>% res()
rasterCellArea <- rasterRes[1] * rasterRes[2] # in m^2
basin_P <- raster::extract(chelsaP_GUNT_corr_raster,gunt_Shapefile)[[1]] * rasterCellArea / 1000
basin_P <- basin_P %>% sum() / areaGunt * 1000 # now in mm
#print(paste0("The bias corrected CHELSA v.1.2 norm precipitation in Gunt River Basin is ", basin_P %>% round(0), ' mm'))
```

From the perspective of the water balance, the basin-wide long-term mean precipitation estimate passes the test since P (353 mm) \> Q (234 mm) where the latter is the long-term discharge norm at the Khorog gauging station at the outlet of the basin (see also Chapter \@ref(CaseStudies) for more information on Gunt river basin). The water balance components are also discussed in Chapter \@ref(LongTermWaterBalance).

As an aside, the bias corrected precipitation climatology shows an interesting feature of the Gunt river basin (see Figure \@ref(fig:guntCHELSAPreciptiation)). Namely, there is a stark precipitation gradient between the western part of the basin where the bulk of the precipitation is observed and the hyper-arid Pamir plateau region to the east, where annual precipitation is around or below 200 mm.

What about the seasonality of the CHELSA product? Can it adequately reproduce the observed precipitation seasonality? If this would not be the case, we would have to reject the validity of the product and explore other high-resolution climatologies such as WorldClim V2 or CHPClim V1 (see [@beck2020b] for more information on these products). Lets explore again for Gunt river basin.

First, we load and prepare all the required station precipitation and geospatial data. Then, we compute the monthly norms of these data for the period 1981-01-01 through 2013-12-31.

```{r precipitationNorms, fig.cap="Monthly precipitation norms of the bias corrected CHELSA v1.2.1 dataset and the mean monthly precipitation averaged over the four meteorological stations in the Gunt river basin."}
# Get data (this time, we access the monthly norm data through the specification of the variable name, that we want to load, i.e. varname="corr_P_monthly") 
fLoc <- './data/AmuDarya/Gunt/ReanalysisData/tp_bcorr_monthly_CHELSA_Gunt.nc'
chelsaP_GUNT_monthly_corr_raster_proj <- brick(fLoc, varname="corr_P_monthly")

# Extract Gunt river basin cells and compute monthly totals
chelsa_monthly_norm_P <- extract(chelsaP_GUNT_monthly_corr_raster_proj,gunt_Shapefile)[[1]] * rasterCellArea / 1000
chelsa_monthly_norm_P <- (chelsa_monthly_norm_P %>% colSums() / areaGunt * 1000) %>% unname() # now in mm
chelsa_monthly_norm_P <- chelsa_monthly_norm_P %>% as_tibble() %>% rename(CHELSA_norm_P=value)

# Load Gunt Station Data record
fPath = './data/AmuDarya/Gunt/StationData/gunt_data_cleaned.Rds'
data <- read_rds(fPath)

# Prepare the station data precipitation record
P_38950 <- data %>% filter(type=="P" & code==38950) %>% dplyr::select(date,data) %>% rename(P_38950=data)
P_38953 <- data %>% filter(type=="P" & code==38953) %>% dplyr::select(date,data) %>% rename(P_38953=data)
P_38954 <- data %>% filter(type=="P" & code==38954) %>% dplyr::select(date,data) %>% rename(P_38954=data)
P_38956 <- data %>% filter(type=="P" & code==38956) %>% dplyr::select(date,data) %>% rename(P_38956=data)

P <- full_join(P_38950,P_38953,by="date")
P <- full_join(P,P_38954,by="date")
P <- full_join(P,P_38956,by="date")

# add a month identifier
P <- P %>% filter(date>=as.Date("1981-01-01") & date<=as.Date("2013-12-31")) %>% mutate(mon = month(date)) %>% 
  dplyr::select(-date)
P <- P %>% pivot_longer(-mon) %>% group_by(mon)

# Now, make a nice plot which compares with the monthly means average over all stations in the catchment.
station_monthly_norm_P <- P %>% summarise(Station_norm_P = mean(value,na.rm=TRUE)) %>% dplyr::select(-mon) 

# Join data
norm_P_data <- chelsa_monthly_norm_P %>% add_column(mon=seq(1,12,1),station_monthly_norm_P,.before = 1)
# Prepare for plotting
norm_P_data_long <- norm_P_data %>% pivot_longer(-mon)
# Plot
ggplot(norm_P_data_long,aes(x=mon,y=value,color = name)) + geom_line() + 
  xlab("Month") + ylab("mm/month")
```

The seasonality of the precipitation is in excellent agreement between the observed data and the bias corrected CHELSA precipitation product. One should not be misled by the offset in absolute terms between the two datasets since since one is data derived from stations at particular locations and the other is average high-resolution gridded data.

A better way to plot the comparison of the seasonality of the two products would be to center and standardize the two datasets. This can be achieved the following way.

```{r precipitationNormsZscore,fig.cap="Centered and standardized precipitation norms for the comparison of the seasonality of the two products.The bias corrected CHELSA product reproduces the precipitation seasonlity in an excellent manner. Note that the values on the y-axis do not have any units as a result of the standarization."}
norm_P_data_zscore <- 
  norm_P_data %>% mutate(Station_norm_P_zscore = (Station_norm_P - mean(Station_norm_P))/ sd(Station_norm_P)) %>% 
  mutate(CHELSA_norm_P_zscore = (CHELSA_norm_P - mean(CHELSA_norm_P)) / sd(CHELSA_norm_P))
norm_P_data_zscore_long <- norm_P_data_zscore %>% dplyr::select(-Station_norm_P,-CHELSA_norm_P) %>% pivot_longer(-mon)
ggplot(norm_P_data_zscore_long,aes(x=mon,y=value,color = name)) + geom_line() + 
  xlab("Month") + ylab("[-]")
```

To summarize, with the CHELSA v1.2.1 dataset, we have downloaded and prepared a high spatial resolution climatology for the Central Asia domain. As this product is derived from reanalysis data that mixes station data with climate model output, the precipitation product was bias corrected for snow undercatch that causes the original reanalysis data to greatly underestimate high-elevation precipitation data. As show for Gunt river basin in the Pamirs, the resulting temperature and precipitation climatologies compare in an excellent manner with seasonalities observed at local meteorological stations.

For hydrological modeling, however, we need not only high spatial resolution data but also high temporal resolution data, ideally at hourly time-steps, to drive the hydrological model. In the next Section \@ref(<Data::ERA5>), we show how hourly ERA5 reanalysis data fields can be resampled and rescaled so that mean or total monthly values match CHELSA v.1.2.1 at particular raster cells. Like this, we will arrive at a dataset with high temporal and spatial resolution.

### ERA5 Download and Data Resampling with PBCORR CHELSA {#Data::ERA5}

#### ERA5 Background

ERA5 data from 1981-01-01 through 2013-12-31 for the Central Asia domain is available for download under this [link](https://www.dropbox.com/sh/5ce1kuque45njav/AABz97dPaA12qamuXQIdjSFEa?dl=0). Hourly temperature 2 meters above the surface (t2m) and hourly precipitation (tp) totals can be downloaded there[^data-5]. More information about ERA5 data can be found on the official [website](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5) of the European Center of Medium Weather Forecast.

[^data-5]: Please note that one raster brick that encompasses the data for one year is approx 333 MB to download!

With the [Lobelia Past Climate Explorer](https://era5.lobelia.earth/en/?utm_source=lobelia&utm_medium=web&utm_campaign=project-button), one can easily get key statistics of any of the ERA5 raster cells globally. Try it! Go to the Central Asia domain, search for your place of interest (i.e. your home, the Gunt river basin, Chirchik river basin, etc.) and click on the point where you would like to see the statistics. See also Figure \@ref(fig:lobeliaERA5)

```{r lobeliaERA5,echo=FALSE,fig.cap="Screenshot from the Lovelia ERA5 website with the ERA5 temperature statistics of Khorog selected.  "}
knitr::include_graphics("_bookdown_files/FIG_DATA/lobelia_era5.jpg")
```

[ERA5 data](https://cds.climate.copernicus.eu/#!/search?text=ERA5&type=dataset) can be downloaded from the Copernicus Climate Change Service (C3S) Climate Data Store. We use the ERA5-Land hourly data from 1981 product. Note that if you want to download the data yourself from the Data Store, you need to register there.

```{r CDStoreERA5, echo=FALSE,fig.cap="Screenshot from the Copernicus Climate Data Store. One needs to register first if you want to download data yourself from the Climate Data Store (click on Login/register button. The product which we download is highlighted. If you click on it, then the detailed data page comes up."}
knitr::include_graphics('_bookdown_files/FIG_DATA/CDStore_ERA5.jpg')
```

As per the ECMWF description, "ERA5-Land is a reanalysis dataset providing a consistent view of the evolution of land variables over several decades at an enhanced resolution compared to ERA5. ERA5-Land has been produced by replaying the land component of the ECMWF ERA5 climate reanalysis. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset using the laws of physics. Reanalysis produces data that goes several decades back in time, providing an accurate description of the climate of the past." For more information, please visit the detailed data description [webpage](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview).

The variables t2m and tp which you can access via this [link](https://www.dropbox.com/sh/5ce1kuque45njav/AABz97dPaA12qamuXQIdjSFEa?dl=0) are described described in greater detail on the site. For reference, these data specifications are copied in the Table below.

| Name                     | Units | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
|--------------------------|-------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 2m temperature (t2m)     | K     | Temperature of air at 2m above the surface of land, sea or in-land waters. 2m temperature is calculated by interpolating between the lowest model level and the Earth's surface, taking account of the atmospheric conditions. Temperature measured in kelvin can be converted to degrees Celsius (Â°C) by subtracting 273.15.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| Total precipitation (tp) | m     | Accumulated liquid and frozen water, including rain and snow, that falls to the Earth's surface. It is the sum of large-scale precipitation (that precipitation which is generated by large-scale weather patterns, such as troughs and cold fronts) and convective precipitation (generated by convection which occurs when air at lower levels in the atmosphere is warmer and less dense than the air above, so it rises). Precipitation variables do not include fog, dew or the precipitation that evaporates in the atmosphere before it lands at the surface of the Earth. This variable is accumulated from the beginning of the forecast time to the end of the forecast step. The units of precipitation are depth in meters. It is the depth the water would have if it were spread evenly over the grid box. Care should be taken when comparing model variables with observations, because observations are often local to a particular point in space and time, rather than representing averages over a model grid box and model time step. |

: ERA5-Land t2m and pr variables descriptions.

#### ERA5-Land Download

Note: This Section just demonstrates how you can order data from Copernicus Climate Data Store. It is not required for you to carry this out in order to access the Central Asia 2m temperature and total precipitation data that has been prepared for this course and is available for download [here](https://www.dropbox.com/sh/5ce1kuque45njav/AABz97dPaA12qamuXQIdjSFEa?dl=0).

The manual data download from the Climate Data Store is tedious. We show here how, with an R-script, you can place a data order and then, once the data is prepared, download it from the Data Store.

The following code segments show to download daily ERA5 t2m and tp data that is segmented into yearly netCDF-files. Like this, these become manageable for later processing. Note that the two code segments start the scripts on the side of the Climate Data Store data service. Following the submission of jobs and after a wait of a couple of hours, the data can then be downloaded at <https://cds.climate.copernicus.eu/cdsapp#!/yourrequests> manually and stored in the relevant location. Note that for these scripts to run, you need to give your own credentials that you obtain after login in the Climate Data Store.

Under the assumption that you have typed in your credentials (user name, ID and key), 2 meter temperature data can be downloaded in the following way.

```{r ERA5CDSt2m, eval=FALSE}
# Required library
library(ecmwfr)
# Prepare data download of ERA5 by adding login credentials to the keychain.
wf_set_key(user = '<Your user name>',
           key = "Your key",
           service = "webapi")


downloadList_t2m <- 1981:2013 # The years for which CHELSA v1.2.1 is available are chosen for download. These will be used for the calibration and vaildation of the hydrological model and constitute the reference hydrological period. 

for (yr in downloadList_t2m){
  CentralAsia_ERA5_hourly_request <- list(
    format = "netcdf",
    variable = c("2m_temperature"),
    year = as.character(yr),
    month = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"),
    day = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31"),
    time = c("00:00", "01:00", "02:00", "03:00", "04:00", "05:00", "06:00", "07:00", "08:00", "09:00", "10:00", "11:00", "12:00", "13:00", "14:00", "15:00", "16:00", "17:00", "18:00", "19:00", "20:00", "21:00", "22:00", "23:00"),
    area = c(45, 64, 34, 81),
    dataset_short_name = "reanalysis-era5-land",
    target = paste0("CentralAsia_ERA5_hourly_",as.character(yr),'.nc'))
  
  file <- wf_request(user     = "Your User ID",   # user ID (for authentication)
                     request  = CentralAsia_ERA5_hourly_request,  # the request name (can be anything)
                     transfer = FALSE,     # put it in the queue and download manually from the website
                     path     = ".",
                     job_name = paste0("t2m_CentralAsia_ERA5_hourly_",as.character(yr),'.nc'))  
}
```

Similarly, total precipitation is downloaded with the following code.

```{r ERA5CDStp, eval=FALSE}
downloadList_tp <- 1981:2013

for (yr in downloadList_tp){
  CentralAsia_ERA5_hourly_request <- list(
    format = "netcdf",
    variable = c("total_precipitation"),
    year = as.character(yr),
    month = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"),
    day = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31"),
    time = c("00:00", "01:00", "02:00", "03:00", "04:00", "05:00", "06:00", "07:00", "08:00", "09:00", "10:00", "11:00", "12:00", "13:00", "14:00", "15:00", "16:00", "17:00", "18:00", "19:00", "20:00", "21:00", "22:00", "23:00"),
    area = c(45, 64, 34, 81),
    dataset_short_name = "reanalysis-era5-land",
    target = paste0("CentralAsia_ERA5_hourly_",as.character(yr),'.nc'))
  
  file <- wf_request(user     = "11732",   # user ID (for authentication)
                     request  = CentralAsia_ERA5_hourly_request,  # the request
                     transfer = FALSE,     # put it in the queue and download manually from the website
                     path     = ".",
                     job_name = paste0("tp_CentralAsia_ERA5_hourly_",as.character(yr),'.nc'))  
}
```

#### Rescaling ERA5 to monthly CHELSA values {#ERA5::BiasCorrectionCHELSA}

ERA5 original data can easily be rescaled (bias corrected) to CHELSA data values for any river basin in the Central Asia domain using the convenience function `riversCentralAsia::biasCorrect_ERA5_CHELSA()`. Type `?biasCorrect_ERA5_CHELSA` to get more information about the function and its arguments. The code block below shows how to rescale (bias correct) total precipitation. It assumes that the ERA5 directory contains two subfolders `ERA5/tp/` and `ERA5/t2m` where the corresponding data are stored.

```{r,eval=FALSE}
# Specify biasCorrect_ERA5_CHELSA() function arguments
basinName <- 'Gunt'
dataType_ERA5 <- 'tp' # note that ERA5 tp units are in m!
## Directories of relevant climate files  - function arguments
dir_ERA5_hourly <- '../HydrologicalModeling_CentralAsia_Data/CentralAsiaDomain/ERA5/'
dir_CHELSA <- '../HydrologicalModeling_CentralAsia_Data/CentralAsiaDomain/CHELSA_V1.2.1/'
# start and end times - function arguments
startY <- 1981
endY <- 2013

biasCorrect_ERA5_CHELSA(dir_ERA5_hourly,dataType_ERA5,dir_CHELSA,startY,endY,basinName,gunt_Shapefile_LatLon)
```

By simply switching the data type (effectively, it just looks for the files in the corresponding directory), temperature can be rescaled to the CHELSA field values for each month.

```{r, eval=FALSE}
# Specify biasCorrect_ERA5_CHELSA() function arguments
basinName <- 'Gunt'
dataType_ERA5 <- 't2m' # note that ERA5 tp units are in m!
## Directories of relevant climate files  - function arguments
dir_ERA5_hourly <- '../HydrologicalModeling_CentralAsia_Data/CentralAsiaDomain/ERA5/'
dir_CHELSA <- '../HydrologicalModeling_CentralAsia_Data/CentralAsiaDomain/CHELSA_V1.2.1/'
# start and end times - function arguments
startY <- 1981
endY <- 2013

biasCorrect_ERA5_CHELSA(dir_ERA5_hourly,dataType_ERA5,dir_CHELSA,startY,endY,basinName,gunt_Shapefile_LatLon)
```

In order to understand if the rescaling of the ERA5 data lead to meaningful results, we can compare monthly precipitation totals from the final ERA5 data to monthly station values, average over the four meteorological stations that we have.

```{r,eval=FALSE}
basinName <- 'Gunt'
dataType_ERA5 <- 'tp' # note that ERA5 tp units are in m!
## Directories of relevant climate files  - function arguments
dir_ERA5 <- '../HydrologicalModeling_CentralAsia_Data/CentralAsiaDomain/ERA5/' # Note: ERA5 data in m
# basin
basin_shp_latlon <- gunt_Shapefile_LatLon
# start and end times - function arguments
startY <- 1981
endY <- 2013
# Date sequence
sTime <- paste0(startY,'-01-01 01:00:00')
eTime <- paste0(endY,'-12-31 23:00:00')
dateSeq_ERA <- seq(as.POSIXct(sTime), as.POSIXct(eTime), by="hour")
dateSeq_ERA <- tibble(date=dateSeq_ERA, data=NA)
dateSeq_ERA <- dateSeq_ERA %>% mutate(month = month(date)) %>% mutate(year = year(date))
# Create Basin subdirectory (if not already existing) to store dedicated annual files there
mainDir <- paste0(dir_ERA5,dataType_ERA5,'/',basinName,'/')
# Start data fetching
for (yr in startY:endY){
  # progress indicator
  print(paste0('PROCESSING YEAR ',yr))
  # file handling
  file2Process_ERA <- paste0(dataType_ERA5,'_ERA5_hourly_',basinName,'_bcorr_',yr,'.nc')
  era_data<- brick(paste0(mainDir,file2Process_ERA))
  # extract the data over the basin
  dateSeq_ERA$data[dateSeq_ERA$year==yr] <- raster::extract(era_data,basin_shp_latlon,fun=mean)
}

dateSeq_ERA_mon <- dateSeq_ERA %>% dplyr::select(date,data) 

if (dataType_ERA5=='t2m'){
  era5_data_mon <- dateSeq_ERA_mon %>% timetk::summarize_by_time(.date_var = date,.by = 'month',era5_data_mon = mean(data),.type = 'ceiling')
  station_data_mon <- data %>% filter(type=='mean(T)' & resolution=='mon') %>%
    dplyr::select(date,data,code) %>%
    filter(date>=(dateSeq_ERA_mon$date %>% first())) %>% 
    filter(date<=(dateSeq_ERA_mon$date %>% last())) %>% 
    pivot_wider(names_from = 'code',values_from = data) %>% 
    mutate(station_data_mon = rowMeans(dplyr::select(.,-date),na.rm=TRUE)) %>% 
    dplyr::select(date,station_data_mon)
} else {
  era5_data_mon <- dateSeq_ERA_mon %>% timetk::summarize_by_time(.date_var = date,.by = 'month',era5_data_mon = sum(data),.type = 'ceiling')
  era5_data_mon$era5_data_mon <- era5_data_mon$era5_data_mon * 1000 # in mm now
  station_data_mon <- data %>% filter(type=='P' & resolution=='mon') %>%
    dplyr::select(date,data,code) %>%
    filter(date>=(dateSeq_ERA_mon$date %>% first())) %>% 
    filter(date<=(dateSeq_ERA_mon$date %>% last())) %>% 
    pivot_wider(names_from = 'code',values_from = data) %>% 
    mutate(station_data_mon = rowMeans(dplyr::select(.,-date),na.rm=TRUE)) %>% 
    dplyr::select(date,station_data_mon)
  
}
era5_data_mon$date <- (era5_data_mon$date - 3600) %>% as.Date()
data_validation <- full_join(era5_data_mon,station_data_mon,by='date')
data_validation %>% pivot_longer(-date) %>% 
  plot_time_series(.date_var = date,.value = value,.smooth = FALSE,
                   .color_var = name,.title = "",.x_lab = "Year",.y_lab = "mm/month",.interactive = FALSE)
```

```{r ComparionERA5rescaledStationTP,echo=FALSE,fig.cap="Comparison of mean monthly precipitation values of the Gunt meteorlogical Stations with the rescaled ERA5 data in the basin. The timeseries compare favorably, both in terms of seasonality and interannual variability."}
knitr::include_graphics('_bookdown_files/FIG_DATA/Comparison_ERA5rescaled_Station_tp_monthly.jpg')
```

#### Downscaling ERA5 to Basin Elevation Bands and Data Export to RS MINERVE Database file {#era5DownscalingDataExportRSMINERVE}

The next and last step for the preparation of the input data required for hydrological modeling in RS MINVERVE involves the downscaling of the prepared hourly ERA5 data to the individual subbasins and elevation bands inside a catchment. The process of generating the input files is shown by using data from the Gunt river basin.

The Gunt river basin outline is shown in Figure \@ref(fig:guntOutline). We want to downscale the prepared hourly ERA5 climate fields over the domain of the Gunt river basin to the individual subbasins and the elevation bands of these subbasins (see Figures \@ref(fig:guntOutline) to \@ref(fig:guntSubbasinsElevationBands) below). In other words, we want to generate hourly climate timeseries of mean temperature and precipitation levels for each subbasin and all of the elevation bands in each subbasin. The hydrological processes of each of these subbasin elevation bands will then be modeled with a separate model. All these individual hydrological models will be interconnected according to the existing flow topology in the basin. Like this, we arrive at a lumped (lumped over the subbasin-specific elevation bands), semi-distributed (distributed between the subbasins and elevation bands) hydrological model of the entire catchment.

```{r guntOutline, echo=FALSE,fig.cap='The outline of the Gunt river catchment is shown with the key river sections of all tributariies from the corresponding subbasins.'}
knitr::include_graphics("_bookdown_files/FIG_DATA/Gunt_Outline.jpg")
```

```{r guntSubbasins, echo=FALSE,fig.cap='Gunt river catchment with the individual subbasins is shown. These subbasins are further divided into elevation band zones and the mean climate finally extracted over these subbasin-specfic elevation bands (see Figure @ref(fig:guntSubasinsElevationBands)).'}
knitr::include_graphics("_bookdown_files/FIG_DATA/Gunt_Subbasins.jpg")
```

```{r guntSubasinsElevationBands, echo=FALSE,fig.cap="The Gunt river catchment elevation bands are shown in red color. The entire catchment was divided into 4 altitude zones with an interval spacing of 1'000 meters. In real world climate impact studies, elevation bands are normally generated with an interval spacing of 200 - 500 meters."}
knitr::include_graphics("_bookdown_files/FIG_DATA/Gunt_Subbasins_ElevationBands.jpg")
```

```{r guntSubbasinsNamingConvention, echo=FALSE,fig.cap='The naming concention of the subbasins is shown. For each subbasin, the bands are identified with a suffix .._b1 for elevation band 1, .._b2 for elevation band 2 and so on.'}
knitr::include_graphics('_bookdown_files/FIG_DATA/Gunt_Topology.jpg')
```

```{r bandAttributeTable, echo=FALSE,fig.cap="Subbasin elevation band attribute table. In total there are 14 elevation bands and for each elevation band, a climate time series is created with the function `riversCentralAsia::generate_ERA5_Subbasins_CSV()`. The Z field is important and specifies the average elevation of the corresponding elevation band for each subbasin."}
knitr::include_graphics('_bookdown_files/FIG_DATA/Gunt_ElevationBands_AttributeTable.jpg')
```

The code block assumes that the previously described steps have been carried and that the corresponding files are stored in the correct relative path locations. First, ERA5 precipitation is downscaled with `generate_ERA5_Subbasin_CSV(...)` with `dataType='tp'` set. Second, `dataType='t2m'` for the downscaling of the 2 meter above surface ERA5 temperature. In a third step, we add the discharge data to the resulting data frame in the last column. Finally, the observed discharge data is added. Note here that we add the gap filled time series of the observational record. The process of gap filling discharge data is described in Section \@ref(StationData::GapFilling) above. All elements have been added to the code block so as to make it self-contained.

```{r, eval=FALSE}
# Housekeeping
dir_ERA5_hourly <- '../HydrologicalModeling_CentralAsia_Data/CentralAsiaDomain/ERA5/'
catchmentName <- 'Gunt'
elBands_shp <- st_read('../HydrologicalModeling_CentralAsia_Data/AmuDarya/Gunt/GeospatialData/Gunt_ElevationBands_Subbasins_RSMinerve.shp')

# Get the discharge data ready
## Load Q data records
fPath = paste0('./data/AmuDarya/Gunt/StationData/')
fName = 'gunt_data_cleaned.Rds'
data <- read_rds(paste0(fPath,fName))
data
q_17050_mon <- data %>% filter(type == "Q" & code == '17050' & resolution == 'mon')
### Gap filling step
q_17050_mon_filled$data[is.na(q_17050_mon$data)] = 
  q_17050_mon_filled$norm[is.na(q_17050_mon$data)] 

## Meteostations
meteoStations <- # just put everything in a regular dataframe
  tibble(StationName=c("Bulunkul","Khorog","Khorog","Javshangoz","Navobod"),
         StationCode = c(38953, 38954, 17050, 38956, 38950),
         lat   = c(37.70416667,37.50361111,37.50361111,37.39083333,37.59416667),
         lon   = c(72.94583333,71.515,71.515,72.29583333,71.86555556),
         utm.x = NA,
         utm.y = NA,
         masl  = c(3746, 2075, 2075,3438, 2566),
         type = c("Meteo", "Meteo","Discharge Gauge","Meteo","Meteo"))
### convert lat / lon coordinates to UTM
cord.dec = SpatialPoints(cbind(meteoStations$lon, meteoStations$lat), proj4string=CRS("+proj=longlat"))
cord.UTM <- spTransform(cord.dec, CRS("+init=epsg:32642"))
cord.UTM.tbl <- cord.UTM %>% as_tibble()
meteoStations$utm.x <- cord.UTM.tbl$coords.x1
meteoStations$utm.y <- cord.UTM.tbl$coords.x2

# Years
startY <- 1981
endY <- 2013

# 1. Downscaling precipitation
dataType <- 'tp' # Precipitation
gunt_db_tp <- generate_ERA5_Subbasin_CSV(dir_ERA5_hourly,catchmentName,dataType,elBands_shp,startY,endY)
# 2. Downscaling temperature
dataType <- 't2m' # Temperature
gunt_db_t2m <- generate_ERA5_Subbasin_CSV(dir_ERA5_hourly,catchmentName,dataType,elBands_shp,startY,endY)
# 3. Joining the two data frames.
gunt_db <- gunt_db_t2m %>% add_column(gunt_db_tp %>% dplyr::select(-Station),.name_repair = 'unique') 
# 4. Adding the observed discharge data in the required format to the data frame
gunt_db_Q <- q_17050_mon_filled %>% dplyr::select(date,data) 
gunt_db_Q$date <- gunt_db_Q$date %>% as.POSIXct() + 22 * 60 * 60 # just adding time so that we are indeed at the end of the month 
datesChar_Q <- posixct2rsminerveChar(gunt_db_Q$date) %>% rename(Station=value)
datesChar_Q <- datesChar_Q %>% add_column(Q_17050 = (gunt_db_Q$data %>% as.character))

gunt_db_Q <- full_join(gunt_db,datesChar_Q,by='Station') # this works well
# now finish off by giving the required attributes in the table for the discharge station
gunt_db_Q$Q_17050[1] = 'Q_17050'
gunt_db_Q$Q_17050[2] = meteoStations$utm.x[2]
gunt_db_Q$Q_17050[3] = meteoStations$utm.y[2]
gunt_db_Q$Q_17050[4] = meteoStations$masl[2]
gunt_db_Q$Q_17050[5] = 'Q'
gunt_db_Q$Q_17050[6] = 'Flow'
gunt_db_Q$Q_17050[7] = 'm3/s'
gunt_db_Q$Q_17050[8] = 'Constant before'

names(gunt_db_Q) <- gunt_db_Q[1,] %>% as.character()
```

The resulting data frame can be stored with `write.table(..,..,sep=',',row.names = FALSE,col.names=FALSE,quote=FALSE)` as a csv-file and the read into RS MINERVE later. A screenshot of the csv-file is below in Figure \@ref(fig:guntCSVFile). Elevation band-specific temperature (T) and precipitation (P) data are stored in columns. The last column contains the discharge data Q. If more than one observation station are available, more discharge columns would correspondingly need to be added.

In row 1 - 8, elevation band specific information is stored. More specifically, the following information is contained:

-   Row 1: Name of elevation band and discharge station(s)

-   Row 2: Longitude of centroid of elevation band and location of gauging station(s) (in meters, UTM)

-   Row 3: Latitude of centroid of elevation band and location of gauging station(s) (in meters, UTM)

-   Row 4: Mean elevation across elevation band and elevation of gauging station(s)

-   Row 5: Observation type indicator (T: temperature, P: precipitation and Q: discharge)

-   Row 6: Category

-   Row 7: Measurement units

-   Row 8: Interpolation method for downsampling course resolution time series[^data-6]

[^data-6]: This is for example used to downsample monthly discharge as provided by the hydrometeorological agency to hourly discharge (we use hourly simulation time steps in the hydrological model).

```{r guntCSVFile, echo=FALSE,fig.cap='Screenshot of the resulting large csv file that can be read into RS MINERVE. '}
knitr::include_graphics("_bookdown_files/FIG_DATA/gunt_RSMINERVE_CSV.jpg")
```

From rows 9 onward, the actual data are stored where a time stamp in the first column corresponds to the corresponding observation data and time.

## Data on Climate Projections

In order to look into the future with a hydrological model for exploring climate scenarios, it needs to be fed with those scenarios. The production of these scenarios in a way resembles the steps described for the reanalysis data but also differs in some marked way. Let us outline them first before diving into the details.

First, a baseline period is defined which serves as a reference against which future climate impacts are assessed. Second, the future period of interest for the investigation of climate impacts needs to be defined and climate scenarios identified that cover the area and period of interest. The future climate scenarios are outputs from global climate models (GCMs). These GCMs normally generate monthly data as a function of representative concentration pathways (called RCPs). They describe possible futures as a function of different atmospheric CO~2~-concentration scenarios.

We focus the discussion here on the RCP 4.5 and RCP 8.5 concentration scenarios. According to the IPCC, RCP 4.5 is an intermediate scenario where CO~2~ emissions peak around 2040, then decline. Compared to this, RCP 8.5 is generally considered to be a worst case climate change scenario. Very detailed information regarding these scenarios, their underlying assumptions and assumptions can be found on the dedicated website served by the Intergovernmental Panel for Climate Change (IPCC). See the link [here](https://ar5-syr.ipcc.ch/topic_futurechanges.php).

```{r rcpGGConcetrationLevels, echo=FALSE,fig.cap='The development of greenhouse gas concentrations during the 21st century as a function of the corresponding scenario. We focus here on RCP4.5 and RCP8.5. Source: [@van_Vuuren_2011]'}
knitr::include_graphics("_bookdown_files/FIG_DATA/greenhouseGasConcetrations_RCP.jpg")
```

### High Res. Monthly Climate Time Series for 2006 - 2100 {#CHELSA21Century}

The recently released high-resolution climate scenario datasets described by [@Karger_2020] are utilized here to study climate impacts in river basins in the Central Asia region. The authors of the aforementioned paper present GCM output for monthly precipitation, mean minimum as well as maximum monthly temperatures that has been downscaled using the CHELSA algorithm.[^data-7] The data can be found here <https://www.envidat.ch/#/metadata/chelsa_cmip5_ts>.

[^data-7]: This is the same algorithm that was used to produce high-resolution reanalysis data as discussed in Chapter \@ref(<Data::ClimateReanalysisData>).

We download data from 3 out of the 4 available downscaled GCM runs for further analysis and processing. These are outputs from the Coupled Model Intercomparison Project phase 5 ([CMIP5](https://www.wcrp-climate.org/wgcm-cmip/wgcm-cmip5)) and are gridded monthly time series from the years 2006 through 2100 with a spatial resolution of 0.049 degrees (see again [@Karger_2020] for all the details). The three models from which data were taken are: CMCC-CM run by the Centro Euro-Mediterraneo per I Cambiamenti Climatici (CMCC); MIROC5 run by the University of Tokyo; and ACCESS1-3 run by the Commonwealth Scientific and Industrial Research Organization (CSIRO) and Bureau of Meteorology (BOM), Australia [@Karger_2020].

First, the data is downloaded and stored locally for RCP 4.5 and RCP 8.5. Then, as in the case of the original CHELSA data (see Section \@ref(ERA5::BiasCorrectionCHELSA), the monthly gridded precipitation time series are bias corrected using the monthly correction factors as report by [@beck2020c] and finally, mean monthly temperature fields are generated from the minimum and maximum monthly temperatures. The resulting data available for the Central Asia domain are available for download via this [link](https://www.dropbox.com/sh/xs870upjjvg9ovv/AABkniqG4f6XFzDkwZqhurcta?dl=0)[^data-8].

[^data-8]: If you download these data, it is advisable to maintain the directory structure as given via the Dropbox link. Please note that the entire directory is 4.79 GB of data.

As in the case of the ERA5 data, these GCM data need to be made available for all the elevation bands. By providing a proper shapefile that contains sub-basin specific elevation bands of a catchment, the function `riversCentralAsia::downscale_ClimPred_monthly_BasinElBands()` can be used to compute these data. The function processes the climate projection raster bricks with precipitation_flux and air_temperature (tasmin, tasmean and tasmax) and computes elevation band statistics. The next code block provides sample code on how to use `riversCentralAsia::downscale_ClimPred_monthly_BasinElBands()`.

Please be aware that if you want to try this locally on your computer, it is required that you download the entire high resolution climate scenarios for the Central Asia on your local machine. The data are available under this [link](https://www.dropbox.com/sh/xs870upjjvg9ovv/AABkniqG4f6XFzDkwZqhurcta?dl=0). The whole process is shown here using a shapefile of the Gunt river basin that explicitly includes Lake Yashikul in the upstream of the basin. In lieu of this example, your own catchment subbasin file can easily be loaded and provided.

```{r,eval=FALSE}
# Data
climScen_Path <- '../HydrologicalModeling_CentralAsia_Data/CentralAsiaDomain/PROJECTIONS/' # This Path would need to be adjusted for in case the directory with the climate projections is stored elsewhere.
rcp <- c('rcp45','rcp85')
cModelList <- c('ACCESS1-3','CMCC-CM','MIROC5')
# Catchment Shapefile
elBands_shp <- st_read('./data/AmuDarya/GuntYashikul/GeospatialData/subbasins_Z.shp')
# Ensure Projection is latlon
elBands_shp_latlon <- sf::st_transform(elBands_shp,crs = sf::st_crs(4326))
# Unused catchments in RSMinerve? Preprocess Shapefile: This is specific for the Gunt-Yashikul model and can be removed if not required or change accordingly.
elBands_shp_latlon <- elBands_shp_latlon %>% dplyr::slice(-1:-3)

# Fancy trick to generate an empty dataframe with column names from a vector of characters.
namesElBands <- elBands_shp_latlon$name
dataElBands_df <- namesElBands %>% purrr::map_dfc(setNames, object = base::list(base::logical())) 

# Start and end years of climate projections
startY <- 2006
endY <- 2100

# Search pattern for file list
fileListSearchPattern <- "2006-2100"

# Generate downscaled climate scenario files and store files in corresponding directory
# RCP45
pathN <- paste0(climScen_Path,'rcp45','/','ACCESS1-3','/')
downscaled_ClimPred_rcp45_ACCESS1_3 <-downscale_ClimPred_monthly_BasinElBands(pathN,fileListSearchPattern,
                                                                              startY,endY,elBands_shp_latlon)

pathN <- paste0(climScen_Path,'rcp45','/','CMCC-CM','/')
downscaled_ClimPred_rcp45_CMCC_CM <- downscale_ClimPred_monthly_BasinElBands(pathN,fileListSearchPattern,
                                                                              startY,endY,elBands_shp_latlon)
pathN <- paste0(climScen_Path,'rcp45','/','MIROC5','/')
downscaled_ClimPred_rcp45_MIROC5 <- downscale_ClimPred_monthly_BasinElBands(pathN,fileListSearchPattern,
                                                                              startY,endY,elBands_shp_latlon)

# RCP85
pathN <- paste0(climScen_Path,'rcp85','/','ACCESS1-3','/')
downscaled_ClimPred_rcp85_ACCESS1_3 <-downscale_ClimPred_monthly_BasinElBands(pathN,fileListSearchPattern,
                                                                              startY,endY,elBands_shp_latlon)
pathN <- paste0(climScen_Path,'rcp85','/','CMCC-CM','/')
downscaled_ClimPred_rcp85_CMCC_CM <- downscale_ClimPred_monthly_BasinElBands(pathN,fileListSearchPattern,
                                                                              startY,endY,elBands_shp_latlon)
pathN <- paste0(climScen_Path,'rcp85','/','MIROC5','/')
downscaled_ClimPred_rcp85_MIROC5 <- downscale_ClimPred_monthly_BasinElBands(pathN,fileListSearchPattern,
                                                                              startY,endY,elBands_shp_latlon)

# Store files if required in the corresponding catchment-specific folder. For the example presented here, this is in the following directory.
# basin_climScen_Path <- './data/AmuDarya/GuntYashikul/ClimateProjections/'
#  
# climScen_fileList <- c('downscaled_ClimPred_rcp45_ACCESS1_3', 'downscaled_ClimPred_rcp45_CMCC_CM',
#                'downscaled_ClimPred_rcp45_MIROC5','downscaled_ClimPred_rcp85_ACCESS1_3',
#                'downscaled_ClimPred_rcp85_CMCC_CM','downscaled_ClimPred_rcp85_MIROC5')
#  
# save(climScen_fileList,list = climScen_fileList,file = paste0(basin_climScen_Path,'climScen_monthly','.rda'))
```

It is important to mention that precipitation is stored in units of kg/m^2^/s in these climate projection data. How do we arrive at mm/month in order to make these data compatible with the ERA5 data? To answer this question, let us make a little thought experiment. What happens when you pour 1 kg of water on a 1 m^2^ big patch? 1 kg corresponds to 1 liter that corresponds to 10^-3^ m^3^. So, very simply, this amount of water poured on such a patch generates a water height of exactly 1 mm. Using this equivalence, we can rewrite the unit kg/m^2^/s to mm/s. Finally, in order to arrive at mm/day, for example, we just multiply the data by 60x60x24 = 86'400 which are the number of seconds in a day. Since the climate model output is in monthly time intervals, we need mm/month and hence would also need to multiply by the number of days in the corresponding month.

As discussed, these GCM data are high spatial resolution monthly future climate fields which we downscaled on the corresponding catchment shapefile with its subbasins and elevation bands. All good. But how do we arrive at climate fields that also have a high temporal resolution (hourly time resolution in this case) so that we can drive the RS MINERVE hydrological model with the required input data? The solution is shown in the following Section \@ref(<Data::WeatherGenerator>) using a weather generator. A weather generator is a stochastic model that produces daily weather variables which can then be converted to hourly fields.

### Using a Weather Generator to Simulate Daily Future Climate {#Data::WeatherGenerator}

#### Background and Input File Generation

Stochastic weather generators are probabilistic models that are used to simulate weather data at a specific site or region by analyzing historical weather data and then generating a time-series of weather variables with statistical properties identical to the historical data [@BIRT20101252]. We demonstrate the use of RMAWGEN, a stochastic weather generator available for the `R` environment. Further information on RMAWGEN can be found here <https://github.com/ecor/RMAWGEN> and under the links provided via the package information on GitHub.

While the weather generator is relatively poorly documented, a useful albeit very technical presentation of the tool is available [here](https://docs.google.com/file/d/0B66otCUk3Bv6V3RPbm1mUG4zVHc/edit). Furthermore, the functions are documented well in the latest development version of the package. The package can be installed in the following way directly from GitHub:

```{r, eval=FALSE,message=FALSE}
# Install GitHub version
library(devtools)
install_github("ecor/RMAWGEN")
library(RMAWGEN)
```

RMAWGEN allows for the generation of daily temperature and precipitation scenarios that are conditioned on monthly climate scenario totals as given by the GCM model outputs. This is the key idea. Using again an example of the Gunt-Yashikul river basin, the following code block shows how to use the function `prepare_RMAWGEN_input_data()` for the preparation of the relevant RMAWGEN input data files so that the weather generator can be run.

```{r, eval = FALSE}
# Load and process RS MINERVE csv database file
filePath <- './data/AmuDarya/GuntYashikul/RSMinerve/'
fileName <- 'Gunt_Yashikul_1981_2013_db.csv'
era5_gunt_yashikul_1 <- read.table(paste0(filePath,fileName),sep=',') %>% as_tibble()

# Deleting unused catchments in the tibble. These catchments are not modeled later in RS MINERVE, so we can safely delete them here. Note that this operation is specific to the Gunt-Yashikul model and does not generalize to other catchments.
idx2del <- 
  (era5_gunt_yashikul[1,]=='Gunt_DS_1')|
  (era5_gunt_yashikul[1,]=='Gunt_DS_2')|
  (era5_gunt_yashikul[1,]=='Gunt_DS_3')
era5_gunt_yashikul <- era5_gunt_yashikul %>% dplyr::select(which(!idx2del))

# Generate the input files for the stochastic weather generator.
station_data <- prepare_RMAWGEN_input_data(era5_gunt_yashikul)
# In case variables in station_data list should not be made available directly on the workspace, on can comment out the following line of code.
station_data %>% list2env(.,envir = .GlobalEnv) # Send list variables to global environment.
```

The function returns a list `rmawgen_input_files` with all key information that can be unlisted using `rmawgen_input_files %>% list2env(.,envir = .GlobalEnv)`. Data returned are:

-   STATION_NAMES: Character vector of station names (effectively, these are just the subbasin names extracted from the RS MINERVE input file).

-   ELEVATION: Mean elevation of the stations

-   STATION_LATLON: Matrix with station names, latitude and longitude

-   LOCATION: Same as the station name, used above.

-   PRECIPITATION: Tibble containing daily precipitation for each station

-   TEMPERATURE_MIN: Minimum daily temperature (calculated from the ERA5 hourly data stored in the RS MINERVE csv file)

-   TEMPERATURE_MAX: Maximum daily temperature (ditto)

A weather generator is a type of model that uses input data to simulate output variables, i.e. daily precipitation and minimum as well as maximum temperatures. Exactly like for example a hydrological runoff model, the stochastic weather generator model depends on input parameters. Different input parameter configuration lead to different model performance / outcomes. How are these parameters calibrated and how is such a model validated when we do not have calibration and validation sets available for the future periods for which climate impacts need to be studied?

The way to do this is to calibrate and validate the stochastic weather generator with reanalysis ERA5 data for each elevation band in the catchment of interest. In other words, we assume that each elevation band contains a representative meteorological station for which we have the ERA5 data available which is used to calibrate and validate daily weather generator models. In this context, the terms *elevation bands* and *meteorological stations* are used interchangeably.

The key question to be answered then is whether or not the model is able to reproduce the statistical characteristics of the ERA5 dataset for each elevation band/station. If yes, we can safely assume that the weather generator can in a more or less realistic manner generate stochastic future daily climate fields that are conditioned on local conditions and on the monthly minimum and maximum temperature and precipitation fields from the climate projections.

A typical parameter set of RMAWGEN for testing different models with different parameters can be specified in the following way.

```{r,eval=FALSE}
# Housekeeping
set.seed(123456) # Random generator seed is set to make results reproducible.

# Monthly climate is calculated if it is set to NULL.
PREC_CLIMATE <- NULL

# Calibration Period
year_min <- 1981
year_max <- 2013
origin <- "1981-1-1" # This is the starting date for which we have data available.

# n GPCA iterations for variable and VAR residuals
n_GPCA_iter <- 5
n_GPCA_iteration_residuals <- 5

# Autoregression orders (p) and exogenous vars
p_test <- 1
p_prec <- 3
exogen <- NULL
exogen_sim <- exogen

# number of weather realizations
nscenario <- 1

# Simulation period
year_min_sim <-  year_min # we are not yet simulating future climate but use the available data for model assessment, hence year_min_sim = year_min
year_max_sim <-  year_max # we are not yet simulating future climate but use the available data for model assessment, hence year_max_sim = year_max

# Minimum Precipitation value below which no precip is considered
valmin <- 1.0
```

The different parameter configurations will be used to run different stochastic weather generator models. In a validation step, the best model will be chosen as explained in the next Section \@ref(StochasticWGEN::ModelCalibrationValidation).

#### Model Calibration & Validation for Model Selection {#StochasticWGEN::ModelCalibrationValidation}

Different parameter combinations can be tested be setting up different models. The performance of the individual models is then assessed as a function of these configurations. We show the process by specifying 4 weather generator models, i.e. `model1` through `model4` and then generate the model output which is finally compared with the observed ERA5 data over the 1981 - 2013 period. The model that reproduces the *observed* ERA5 data in the best possible manner is then selected as the final weather generator model. The process is demonstrated here for the Gunt-Yahsikul river basin[^data-9].

[^data-9]: Detailed information about the core functions of RMAWGEN can be obtained by consulting their help, i.e. by for example typing `?ComprehensivePrecipitationGenerator`.

```{r,eval=FALSE,message=FALSE}
# P03GPCA_prec
model1 <- ComprehensivePrecipitationGenerator(
  station = STATION_NAMES,
  prec_all = PRECIPITATION,
  year_min = year_min,
  year_max = year_max,
  p = p_prec,
  n_GPCA_iteration = n_GPCA_iter,
  n_GPCA_iteration_residuals = n_GPCA_iteration_residuals, 
  exogen = exogen,
  exogen_sim = exogen_sim, 
  sample = "monthly",
  mean_climate_prec = PREC_CLIMATE,
  no_spline = FALSE,
  year_max_sim = year_max_sim,
  year_min_sim = year_min_sim
  )

# P01GPCA
model2 <- ComprehensivePrecipitationGenerator(
  station = STATION_NAMES,
  prec_all = PRECIPITATION,
  year_min = year_min,
  year_max = year_max,
  p = p_test,
  n_GPCA_iteration = n_GPCA_iter,
  n_GPCA_iteration_residuals = n_GPCA_iteration_residuals, 
  exogen = exogen,
  exogen_sim = exogen_sim, 
  sample = "monthly",
  mean_climate_prec = PREC_CLIMATE,
  no_spline = FALSE,
  year_max_sim = year_max_sim,
  year_min_sim = year_min_sim
  )

# P03
model3 <- ComprehensivePrecipitationGenerator(
  station = STATION_NAMES,
  prec_all = PRECIPITATION,
  year_min = year_min,
  year_max = year_max,
  p = p_prec,
  n_GPCA_iteration = 0,
  n_GPCA_iteration_residuals = 0, 
  exogen = exogen,
  exogen_sim = exogen_sim, 
  sample = "monthly",
  mean_climate_prec = PREC_CLIMATE,
  no_spline = FALSE,
  year_max_sim = year_max_sim,
  year_min_sim = year_min_sim
  )

# P01
model4 <- ComprehensivePrecipitationGenerator(
  station = STATION_NAMES,
  prec_all = PRECIPITATION,
  year_min = year_min,
  year_max = year_max,
  p = p_test,
  n_GPCA_iteration = 0,
  n_GPCA_iteration_residuals = 0, 
  exogen = exogen,
  exogen_sim = exogen_sim, 
  sample = "monthly",
  mean_climate_prec = PREC_CLIMATE,
  no_spline = FALSE,
  year_max_sim = year_max_sim,
  year_min_sim = year_min_sim
  )
```

The performance of the 4 models can be assessed with statistical tests and graphically, with qq-plots and through the comparison of simulated versus observed monthly precipitation totals. Results are shown in the Figures below.

```{r rmawgenMonthlyTotals, echo=FALSE,fig.cap="The comparison of the 4 stochastic weather generator models in terms of their abilities to reproduce monthly precipitation totals is shown for one station (elevation band Alishur_2) in the Gunt river basin. Measured monthly totals (mes) are shown on the x-axis and simulated monthly totals (sim) on the y-axis. Results indicate that precipitation totals from the models 1 and 2 are overestimated. In comparison, results from the models 3 and 4 are more balanced and not biased."}
knitr::include_graphics("./_bookdown_files/FIG_DATA/RMAWGEN_Models_monthlyTotalsComparison.jpg")
```

```{r rmawgenQQPlot, echo=FALSE,fig.cap="QQ-Plots of the four model results. If data plots along the diagonal line, it is an indication that the probability distribution of the simluated precipptation (y-axis) is the same as the probability distribution of the observed ERA5 precipitation (x-axis). QQ-plots of models 1 and 2 show a heavy bias whereas model 4 shows an overal satisfactory fit and thus performance. "}
knitr::include_graphics("./_bookdown_files/FIG_DATA/RMAWGEN_Models_qqplot.jpg")
```

All four models pass the multivariate Portmanteau and Breusch-Godfrey (Lagrange Multiplier) tests, which verify the absence of time-autocorrelation of the VAR(p) residuals in the modeled precipitation time series (seriality test). Furthermore, all models pass the Jarque-Bera multivariate skewness and kurtosis test, which validate the multivariate Gaussian probability distribution of the VAR(p) residuals (normality test). See [@Pfaff_2008] for more information.

Figure \@ref(fig:rmawgenMonthlyTotals) and Figure \@ref(fig:rmawgenQQPlot) show that the Model 4 provides an overall well-balanced performance. We will thus us this models to generate the future climate fields in the Gunt river basin.

Temperature is not independent of precipitation and vice versa. The two climate state variables and their changes are interlinked. In the warm season over continents, higher temperatures accompany lower precipitation amounts and vice versa. Hence, over land, strong negative correlations dominate, as dry conditions favor more sunshine and less evaporative cooling, while wet summers are cool (see e.g. IPCC Fourth Assessment Report: Climate Change 2007, Working Group I, The Physical Science Basis, Section 3.3.5, available [here](https://archive.ipcc.ch/publications_and_data/ar4/wg1/en/ch3s3-3-5.html)). Simply put, on rainy cloudy days, there is less radiation for warming the earth surface and vice versa.

This coupling needs to be taken into account when simulating weather. Therefore, we use the `model4` configuration to first generate multi-site synthetic future precipitation time series. Second, we use precipitation as exogenous predictors in the temperature generation step (tasmin and tasmax). Like this, we can coupled temperature simulation to precipitation. If the results are satisfactory, we proceed with this stochastic weather model to produce future simulated weather runs that are conditioned on GCM output for the mid-21st (Period 1) and end of 21st century (Period 2).

#### Coupling Precipitation Realizations with Temperature

For initiating and running the weather generator, the `riversCentralAsia::wgen_daily_PT()` function can be used. It is a wrapper function that minimizes code reuse and allows to easily run RMAWGEN for the baseline period and/or for the future target period of the climate scenario under consideration. The use of the function is demonstrated below for a subset of 2 out of the complete set of all 17 stations in the Gunt-Yashikul catchment.

```{r, eval=FALSE, message=FALSE}
# 1. Station Data
## Load and process RS MINERVE csv database file
filePath <- './data/AmuDarya/GuntYashikul/RSMinerve/'
fileName <- 'Gunt_Yashikul_1981_2013_db.csv'
era5_gunt_yashikul <- read.table(paste0(filePath,fileName),sep=',') %>% as_tibble()

## Delete unused catchments in the Gunt-Yashikul hydrological model (this is specific to the model and does not need to be carried out normally)
idx2del <- (era5_gunt_yashikul[1,]=='Gunt_DS_1') | (era5_gunt_yashikul[1,]=='Gunt_DS_2') | 
  (era5_gunt_yashikul[1,]=='Gunt_DS_3')
era5_gunt_yashikul <- era5_gunt_yashikul %>% dplyr::select(which(!idx2del))

## Generate list containing all station data (this is an input to the wgen_daily_PT() function)
station_data <- prepare_RMAWGEN_input_data(era5_gunt_yashikul)

# 2. RMAWGEN PARAMETERS
## Note: all parameteres are stored in the param list
param <- list()
## Random generator seed
param$seed <- 123456
## Monthly climate is calculated if it is set to NULL
param$PREC_CLIMATE <- NULL
## Calibration Period
param$year_min <- 1981
param$year_max <- 2013
param$origin <- "1981-1-1"
## n GPCA iterations for variable and VAR residuals
param$n_GPCA_iter <- 0
param$n_GPCA_iteration_residuals <- 0
param$n_GPCA_iter_prec <- 0
param$n_GPCA_iteration_residuals_prec <- 0
## Autoregressive order (p)
param$p <- 1
# number of weather realizations
param$nscenario <- 1
# Multi-site stations
param$station <- station_data$STATION_NAMES
# Minimum precipitation cutoff value, i.e. threshold value below which a no precipitation event is recorded [in mm/day]
param$valmin <- 1.0

# 3. Compute stochastic weather for a subset of 2 sample stations for the calibration period 1981 - 2013
clim_scen <- NULL # We not yet simulate future climate. This follows in the next Subsection below.
station_subset <- station_data$STATION_NAMES[1:2] # Selecting 2 example stations, i.e. Alishur_2 and Alishur_3. Normally, one wants to run the function for all stations.

# Return VAR model? If we set this parameter to false, the output size of the PT_sim variable will be greatly reduced. 
param$returnVARModel = FALSE
# Fire up the stochastic VAR machine
PT_sim <- wgen_daily_PT(param,station_data,station_subset,clim_scen,param$returnVARModel)
```

The output of `RMAWGEN::ComprehensivePrecipitationGenerator()` and `RMAWGEN::ComprehensivePrecipitationGenerator()` are stored in the `PT_sim` list. Summary statistics of the resulting simulated climate can be obtained by using the `riversCentralAsia::wgen_daily_summaryStats()` function. For this, the period of interest for comparison (we call this *baseline period*) needs to be specified by setting `param$year_min_Baseline` and `param$year_max_Baseline` as shown below. For each station in the station subset, summary statistics can be shown.

<!--# Housekeeping -->

<!--# SAVING the PT_sim file for later processing -->

```{r, message=FALSE, echo=FALSE, eval=FALSE}
pathF <- './data/AmuDarya/GuntYashikul/ClimateProjections/'
save(PT_sim,list = 'PT_sim',file = paste0(pathF,'PT_sim','.rda'))
save(param,list = 'param',file = paste0(pathF,'param','.rda'))
save(station_data,list = 'station_data',file = paste0(pathF,'station_data','.rda'))
save(station_subset,list = 'station_subset',file = paste0(pathF,'station_subset','.rda'))
```

<!--# LOADING the PT_sim file for later processing -->

```{r, message = FALSE, echo=FALSE}
pathF <- './data/AmuDarya/GuntYashikul/ClimateProjections/'
load(paste0(pathF,'PT_sim.rda'))
load(paste0(pathF,'param.rda'))
load(paste0(pathF,'station_data.rda'))
load(paste0(pathF,'station_subset.rda'))
```

<!--# END HOUSEKEEPING -->

```{r}
param$year_min_Baseline <- 2004
param$year_max_Baseline <- 2013

clim_scen <- NULL

# Computing the baseline statistics and comparing it with simulated weather over the same period.
summaryStats <- wgen_daily_summaryStats(PT_sim, param, station_data, station_subset,clim_scen)
# Summary statistics for the station (i.e. elevation band) Alishur_2 
summaryStats$Alishur_2
```

The `â¦_obs` identifier refers to the baseline period statistics of the observations (ERA5 data in our case). Converse to this, the `â¦_sim` identifier refers to the statistics of generated synthetic climate variable time series using `RMAWGEN`. The variable `clim_scen` is set to `NULL` since we are not (yet) comparing baseline observed climate with future climate scenarios (see Section \@ref(FutureDailyClimateSim) below where this is done).

A graphical comparison of observed monthly versus simulated monthly precipitation values is shown below in Figure \@ref(fig:rmawgenMonthlyTotals) for one elevation band, i.e. the Alishur_2 station. The scatter plot comparing monthly total observed versus simulated precipitation totals does not show a systematic bias. Furthermore, the seriality and normality tests are both passed. We thus consider the simulation results of the weather generator adequately represent local climate conditions.

```{r rmawgenMonthlyTotalsCoupledModel, echo=FALSE, fig.cap = "Comparison of monthly observed (ERA5) precipitation values with simulated ones. No systematic bias is visible."}
knitr::include_graphics("./_bookdown_files/FIG_DATA/RMAWGEN_Models_CoupledModel_monthlyTotalsComparison.jpg")
```

#### Simulating Future Daily Climate {#FutureDailyClimateSim}

Using the insights gained so far, we can now generate future *daily* weather conditioned on the high resolution GCM output as described in the Section \@ref(CHELSA21Century) above. For the climate impact assessment, we generate a 10-year mid 21st century run from 2051 - 2060 (called Period 1) and an end of 21st century run (2091 - 2100, Period 2) for both, the RCP 4.5 and RCP 8.5 concentration pathways. The climate scenarios will be compared to a baseline climate period from 2004 - 2013. These periods are specified in the following way in the parameters `param` list.

```{r}
# Simulation periods
param$year_min_Baseline <- 2004
param$year_max_Baseline <- 2013
param$year_min_sim_Period1 <-  2051
param$year_max_sim_Period1 <-  2060
param$year_min_sim_Period2 <-  2091
param$year_max_sim_Period2 <-  2100
```

Now we are ready to prepare the climate scenarios[^data-10]. The function `riversCentralAsia::climateScenarioPreparation_RMAWGEN()` prepares 2 climate scenarios between the years 2006 - 2100 where the user can define the periods of interest. Here, we want to investigate the 2 scenarios for the mid-21st century and the end of the century as defined above with the `param$year_min_sim_Periodx` and `param$year_min_sim_Periodx` parameters.

[^data-10]: The prepared monthly climate scenarios of this RS MINVERVE model can be found in this directory `'./data/AmuDarya/GuntYashikul/ClimateProjections/'`. Since RMAWGEN requires precipitation, mean minimum and mean maximum temperature on a monthly basis, these data are prepared using the function `riversCentralAsia::climateScenarioPreparation_RMAWGEN()` for the periods of interest in the future.

```{r}
basin_climScen_Path <- './data/AmuDarya/GuntYashikul/ClimateProjections/'
basin_climScen_File <- 'climScen_monthly'

clim_scen <- climateScenarioPreparation_RMAWGEN(basin_climScen_Path,basin_climScen_File,param)
```

We have now defined the 12 precipitation and temperature scenarios, i.e. 2 for each RCP, 3 for each of the climate models available and 2 for each of the periods of interest, 2051 - 2060 and 2091-2100 and can rerun the stochastic weather generator while conditioning the scenarios on the mean future weather states.

```{r, eval = FALSE}
# Compute for all stations
station_subset <- NULL # We compute climate projections for all subasin elevation bands.

# Return VAR model?
param$returnVARModel = FALSE

# Fire up the stochastic weather generator for all climate scenarios
PT_sim_all <- list()
# Loop through all climate scenarios and run models
for (idx in 1:length(clim_scen)){
  PT_sim_all[[idx]] <- wgen_daily_PT(param,station_data,station_subset,clim_scen[[idx]],param$returnVARModel)
}

names(PT_sim_all) <- names(clim_scen)
```

<!--# HOUSEKEEPING -->

<!--# SAVING FILES -->

```{r, message=FALSE, echo=FALSE, eval=FALSE}
# Making simulation results available for loading without recomputing.
pathF <- './data/AmuDarya/GuntYashikul/ClimateProjections/'
save(PT_sim_all,list = 'PT_sim_all',file = paste0(pathF,'PT_sim_all','.rda'))
save(param,list = 'param',file = paste0(pathF,'param_sim_all','.rda'))
```

<!--# LOADING FILES -->

```{r, message=FALSE, echo=FALSE}
# Making simulation results available for loading without recomputing.
pathF <- './data/AmuDarya/GuntYashikul/ClimateProjections/'
load(paste0(pathF,'PT_sim_all.rda'))
load(paste0(pathF,'param_sim_all.rda'))
```

<!--# END HOUSEKEEPING -->

The `PT_sim_all` list contains the simulated daily minimum and maximum temperatures as well as precipitation values for the future periods of interest. In our case, these are the 10-year periods from 2051-2060 and 2091-2100 for all 3 available GCM models and the two RCPs. Summary statistics can be obtained for all scenarios and all stations with the `riversCentralAsia::wgen_daily_summaryStats()` function. This allows to carry out different types of top-level quick analyses for getting a good understanding of the future climate in the basin under consideration as a function of the target period and the GCM as well as the RCP. We show a couple of these analyses here.

First, all summary statistics are produced.

```{r}
PT_sim_stats <- list()
for (idx in 1:length(clim_scen)){
  PT_sim_stats[[idx]] <- 
    riversCentralAsia::wgen_daily_summaryStats(PT_sim_all[[idx]],param,station_data,station_subset,clim_scen[[idx]])
}
names(PT_sim_stats) <- names(clim_scen)
```

Before we show how to do some quick analyses, it should be remembered that we use the following definitions: - Baseline Period: 2004 - 2013; future Period 1: 2051 - 2060; and Future Period 2: 2091 - 2100.

For the station/elevation band Alishur_2, we get the following statistics of the daily climate projections under the GCM MIROC5 and RCP 45:

```{r}
PT_sim_stats$rcp45_MIROC5_Period1$Alishur_2
```

When comparing precipitation for the baseline period and the 2051 - 2060 period, the MIROC5 model suggests a slight increase of precipitation values in the Eastern Pamirs relative to the baseline (please note that the precipitation values in the table are in mm/day). At the same time, minimum mean temperatures are increasing from -10.89 degrees Celsius to -7.15 degrees Celsius, i.e. and increase of a remarkable 3.74 degrees. Our gut feeling tells us that this increase will be even more pronounced at the end of the 21st century and under RCP85. Let's check!

First, we display the summary statistics for Alishur_2 of the GCM MIROC5 and the RCP45 for Period 2. As is visible in the table below, no significant changes are expected in terms of mean precipitation, also in Period 2 under this climate scenario and for this model. However, a further warming is expected where minimum mean temperatures increase to -6.38 degrees Celsius and and the mean maximum temperatures increase from 3.56 to 4.39 degrees Celsius. This suggests a pronounced winter warming.

```{r}
PT_sim_stats$rcp45_MIROC5_Period2$Alishur_2
```

Finally, we do the same for this station/elevation band using the GCM MIROC5 and the RCP85 for Period 2.

```{r}
PT_sim_stats$rcp85_MIROC5_Period2$Alishur_2
```

It can easily be seen that our intuition from above is correct and that the modeling results for example suggest a 7.71 degrees warming of the minimum mean temperatures over this period. At the same time, the model suggests that mean precipitation is slightly increasing from approx. 245 mm/year to 298 mm/year. This corresponds to an increase of approx. 22 % relative to the baseline.

With a projected mean precipitation of 332 mm/year (increase of approx. 36 % relative to baseline), the GCM ACCESS1_3 projects the most pronounced increase in precipitation for Alishur_2 under the RCP85 for the period 2091-2100. The GCM CMCC_CM even suggests a slight decrease of total annual precipitation relative to the baseline. While precipitation projections of GCMs are notoriously uncertain, one relatively robust conclusion to make is that precipitation levels are expected to stay at the current levels or slightly increase. All these findings now require us to study with great care implications on the hydrology of the river basins in the region.

```{r}
PT_sim_stats$rcp85_ACCESS1_3_Period2$Alishur_2
PT_sim_stats$rcp85_CMCC_CM_Period2$Alishur_2
```

For this purpose, we convert these daily climatologies into hourly ones and export them as scenario files that can be read into RS MINERVE where we can perform hydrological scenario analysis. The downscaling to hourly values as well as the exporting is shown in the Section below.

#### Exporting Climate Scenarios as .csv-files for import in RS MINERVE

For exporting to RS MINERVE, a .csv file needs to be generated very much alike the one described in Section \@ref(era5DownscalingDataExportRSMINERVE). Prior to exporting such scenario-dependent files, we need to generate hourly time series from the daily simulated ones. To do this, different approaches are chosen for the precipitation values as well as the temperature time series. The conversion can automatically be done with the helper function `riversCentralAsia::generateHourlyFromDaily_PT()` that accepts the daily climate scenarios as variable from which it downscales to hourly data and prepares the tabular export as .csv-file for later import in RS MINVERVE.

As for total daily precipitation [mm/day], it is available for each day for the future periods of interest and for each station/elevation band. `riversCentralAsia::generateHourlyFromDaily_PT()` converts these values by uniformly distribution the total daily precipitation over the 24 hours within one day, i.e. from `00:00:00` to `23:00:00`. More details on this can be found in the help section of the function.

For temperature, the challenge is a bit bigger since we ideally would want to take into account the diurnal cycle of temperature to vary between the daily minimum and maximum temperatures characteristically. How to get the diurnal cycle for the stations/elevation bands?

What is being proposed here is to use the hourly ERA5 data over the baseline period and to extract a mean dirurnal cycle for each station there measured over all baseline period observation days. Under the assumption that these station cycles remain the same in the future, they are adjusted for each day so that minimum and maximum daily temperatures from the climate scenarios correspond to minimum and maximum diurnal cycle values. As is shown below, the function `riversCentralAsia::computeDiurnalTemperatureCycle()` computes these diurnal station cycles.

```{r, message=FALSE}
filePath <- './data/AmuDarya/GuntYashikul/RSMinerve/'
fileName <- 'Gunt_Yashikul_1981_2013_db.csv'
era5_gunt_yashikul <- read.table(paste0(filePath,fileName),sep=',') %>% as_tibble()

# Subcatchment suspects to delete because we do not use them in the RR Model
idx2del <- (era5_gunt_yashikul[1,]=='Gunt_DS_1')|(era5_gunt_yashikul[1,]=='Gunt_DS_2')|
  (era5_gunt_yashikul[1,]=='Gunt_DS_3')
era5_gunt_yashikul <- era5_gunt_yashikul %>% dplyr::select(which(!idx2del))

# Compute diurnal cycle
diurnalCycle <- computeDiurnalTemperatureCycle(era5_gunt_yashikul,param)

# Simple visualization
diurnalCycle %>% pivot_longer(-hour) %>% group_by(name) %>% 
  ggplot(.,aes(x=hour,y=value,colour=name)) + geom_line() + labs(title="ERA5 Diurnal T Variation, Gunt-Yashikul River Subbasins")
```

Using `riversCentralAsia::generateHourlyFromDaily_PT()`, the daily climate scenario files can be produced in a very simple manner.

```{r,message=FALSE,eval=FALSE}
# Producing the hourly climate scenarios
climScen_hourly <- generateHourlyFromDaily_PT(PT_sim_all,era5_gunt_yashikul,param)
# Adding the required header information to the data frames for each climate scenario
headerRows<- era5_gunt_yashikul[1:8,] %>% dplyr::select(-which(era5_gunt_yashikul[5,]=='Q'))
climScen_hourly_rsminerve <- list()
for (idx in 1:length(climScen_hourly)){
  climScen2Export <- climScen_hourly[[idx]] %>% mutate(across(everything(), as.character))
  names(climScen2Export) <- names(headerRows)
  climScen_hourly_rsminerve[[idx]] <- headerRows %>% add_row(climScen2Export)
}
names(climScen_hourly_rsminerve) <- names(clim_scen)
```

Now, finally, we can store these files as climate scenario files on the disk for later importing into RS MINERVE.

```{r, eval=FALSE}
outputPath <- './data/AmuDarya/GuntYashikul/RSMinerve/' # Specify the output path of the files
names2Save <- names(climScen_hourly_rsminerve) # Specification of the file names (do not change)
names2Save_prefix <- 'Gunt_Yashikul_' # Change according to the basin that you are working with
for (idx in 1:length(climScen_hourly_rsminerve)){
  fileName <- paste0(names2Save_prefix,names2Save[idx],'.csv')
  write.table(climScen_hourly_rsminerve[[idx]],
              paste0(outputPath,fileName),sep=',',
              row.names = FALSE,col.names=FALSE,
              quote=FALSE,append=FALSE)
}
```

## Snow Cover Data

Section is work in progress! Stay tuned.

## Glacier Data

Section is work in progress! Stay tuned.
